本项目基于MobileNetV3-small模型与迁移学习技术，在极少数据量的条件下，完成准确的图像分类。

在实际应用中像医学影像分析、野生动物识别等小数据场景非常常见
而传统深度学习模型往往依赖大量数据，小样本条件下的训练效果受限，容易导致过拟合。因此，本项目提出：在每类8张训练图片的情况下，完成5类物体的分类任务，尝试提升深度学习在小数据环境下的适应能力。


为了解决小样本下的训练困难的问题，我采用了迁移学习策略。具体来说，使用在ImageNet大规模数据集上预训练好的MobileNetV3-small模型，因其具有参数量小、推理速度快的优势，非常适合小样本快速微调。在训练过程中，我冻结了特征提取层，仅微调分类头，从而快速适应新任务，并显著减少了对大量数据的需求。这种方法有效防止了小样本数据下的过拟合，确保了模型的泛化性能。

在数据准备方面，我选定了5个类别，分别是书、猫、狗、花和飞机。每类包含8张训练图和2张验证图，符合Few-shot Learning的设定。为了弥补样本数量不足的缺陷，我应用了基础的数据增强策略：统一图像尺寸到224×224像素，添加随机水平翻转，提升模型的泛化能力。同时，按照PyTorch的ImageFolder标准组织了数据集，确保了训练和验证阶段数据的规范加载。

在训练设置上，除了迁移学习策略，为了在小批量数据训练中保持稳定，我使用了具备自适应学习率机制的 Adam优化器。损失函数使用了适合多类别分类任务的交叉熵损失，训练了5个Epoch。每一轮训练后，我记录当前训练损失（Loss），并在训练结束后绘制了完整的Loss下降曲线。通过这种实时监控，我能够及时发现模型是否存在过拟合或欠拟合问题。训练完成后，将模型权重保存，为后续推理和测试提供支持。

从训练曲线来看，Loss在5个Epoch内快速下降并趋于稳定，验证了迁移学习在小样本环境下的有效性。推理阶段，模型能够准确分类绝大部分验证集样本，区分了不同样本的类别，表现稳定。说明了预训练特征加微调分类头的策略，在小数据环境下依然可以取得良好的分类效果，同时也表明：MobileNetV3-small所具有的轻量化的特性，保证了训练和推理的高效性，非常适合资源受限环境应用。
